Write an application using HBase and HiveQL for flight information system which will 
include
a. Create Flight Info Hbase Table(with Flight information, schedule, and delay)
b. Demonstrate Creating, Dropping, and altering Database tables in Hbase
c. Creating an external Hive table to connect to the HBase for Flight Information Table
d. Find the total departure delay in Hive
e. Find the average departure delay in Hive
f. Create index on Flight information Table



[cloudera@quickstart ~]$ hbase shell
2024-05-09 04:06:20,810 INFO  [main] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 1.2.0-cdh5.13.0, rUnknown, Wed Oct  4 11:16:18 PDT 2017

hbase(main):001:0> list
TABLE                                                                           
flight                                                                          
1 row(s) in 1.0220 seconds

=> ["flight"]
hbase(main):002:0> create 'flight', 'finfo', 'fsch'

ERROR: Table already exists: flight!

Creates a table. Pass a table name, and a set of column family
specifications (at least one), and, optionally, table configuration.
Column specification can be a simple string (name), or a dictionary
(dictionaries are described below in main help output), necessarily 
including NAME attribute. 
Examples:

Create a table with namespace=ns1 and table qualifier=t1
  hbase> create 'ns1:t1', {NAME => 'f1', VERSIONS => 5}

Create a table with namespace=default and table qualifier=t1
  hbase> create 't1', {NAME => 'f1'}, {NAME => 'f2'}, {NAME => 'f3'}
  hbase> # The above in shorthand would be the following:
  hbase> create 't1', 'f1', 'f2', 'f3'
  hbase> create 't1', {NAME => 'f1', VERSIONS => 1, TTL => 2592000, BLOCKCACHE => true}
  hbase> create 't1', {NAME => 'f1', CONFIGURATION => {'hbase.hstore.blockingStoreFiles' => '10'}}
  hbase> create 't1', {NAME => 'f1', IS_MOB => true, MOB_THRESHOLD => 1000000, MOB_COMPACT_PARTITION_POLICY => 'weekly'}

Table configuration options can be put at the end.
Examples:

  hbase> create 'ns1:t1', 'f1', SPLITS => ['10', '20', '30', '40']
  hbase> create 't1', 'f1', SPLITS => ['10', '20', '30', '40']
  hbase> create 't1', 'f1', SPLITS_FILE => 'splits.txt', OWNER => 'johndoe'
  hbase> create 't1', {NAME => 'f1', VERSIONS => 5}, METADATA => { 'mykey' => 'myvalue' }
  hbase> # Optionally pre-split the table into NUMREGIONS, using
  hbase> # SPLITALGO ("HexStringSplit", "UniformSplit" or classname)
  hbase> create 't1', 'f1', {NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}
  hbase> create 't1', 'f1', {NUMREGIONS => 15, SPLITALGO => 'HexStringSplit', REGION_REPLICATION => 2, CONFIGURATION => {'hbase.hregion.scan.loadColumnFamiliesOnDemand' => 'true'}}
  hbase> create 't1', {NAME => 'f1', DFS_REPLICATION => 1}

You can also keep around a reference to the created table:

  hbase> t1 = create 't1', 'f1'

Which gives you a reference to the table named 't1', on which you can then
call methods.


hbase(main):003:0> disable 'flight'
0 row(s) in 6.2930 seconds

hbase(main):004:0> drop 'flight'
0 row(s) in 10.1780 seconds

hbase(main):005:0> create 'flight', 'finfo', 'fsch'
0 row(s) in 4.4190 seconds

=> Hbase::Table - flight
hbase(main):006:0> put 'flight',2,'finfo:source','nashik'
0 row(s) in 1.2930 seconds

hbase(main):007:0> put 'flight',2,'finfo:dest','alibag'
0 row(s) in 1.0550 seconds

hbase(main):008:0> put 'flight',2,'finfo:year','2025'
0 row(s) in 0.0220 seconds

hbase(main):009:0> put 'flight',2,'fsch:at','2:00 PM'
0 row(s) in 0.1110 seconds

hbase(main):010:0> put 'flight',2,'fsch:dt','3:00 PM'
0 row(s) in 0.0140 seconds

hbase(main):011:0> put 'flight',2,'fsch:delay',60
0 row(s) in 0.0740 seconds

hbase(main):012:0> put 'flight',1,'finfo:source', 'alibag'
0 row(s) in 0.0170 seconds

hbase(main):013:0> put 'flight',1,'finfo:dest', 'Pune'
0 row(s) in 0.0270 seconds

hbase(main):014:0> put 'flight',1,'finfo:dest', '2024'
0 row(s) in 0.0370 seconds

hbase(main):015:0> put 'flight',1,'fsch:at', '7:30 AM'
0 row(s) in 0.0310 seconds

hbase(main):016:0> put 'flight',1,'fsch:dt', '12:30 PM'
0 row(s) in 0.1890 seconds

hbase(main):017:0> put 'flight',1,'fsch:delay', '30'
0 row(s) in 0.0200 seconds

hbase(main):018:0> scan 'flight'
ROW                   COLUMN+CELL                                               
 1                    column=finfo:dest, timestamp=1715253388203, value=2024    
 1                    column=finfo:source, timestamp=1715253353944, value=alibag
 1                    column=fsch:at, timestamp=1715253412362, value=7:30 AM    
 1                    column=fsch:delay, timestamp=1715253444126, value=30      
 1                    column=fsch:dt, timestamp=1715253430253, value=12:30 PM   
 2                    column=finfo:dest, timestamp=1715253119953, value=alibag  
 2                    column=finfo:source, timestamp=1715253096346, value=nashik
 2                    column=finfo:year, timestamp=1715253146382, value=2025    
 2                    column=fsch:at, timestamp=1715253196355, value=2:00 PM    
 2                    column=fsch:delay, timestamp=1715253296654, value=60      
 2                    column=fsch:dt, timestamp=1715253245533, value=3:00 PM    
2 row(s) in 0.0510 seconds

hbase(main):019:0> put 'flight',3,'finfo:source', 'Pune'
0 row(s) in 0.0740 seconds

hbase(main):020:0> put 'flight',3,'finfo:dest', 'Nagar'
0 row(s) in 0.0140 seconds

hbase(main):021:0> put 'flight',3,'finfo:year', 2024
0 row(s) in 0.0170 seconds

hbase(main):022:0> put 'flight',3,'fsch:at', '4:00 PM'
0 row(s) in 0.0270 seconds

hbase(main):023:0> put 'flight',3,'fsch:dt', '7:00 PM'
0 row(s) in 0.0180 seconds

hbase(main):024:0> put 'flight',3,'fsch:delay', 10
0 row(s) in 0.0270 seconds

hbase(main):025:0> delete 'flight','1','fsch:delay',1212122333
0 row(s) in 0.1800 seconds

hbase(main):026:0> scan 'flight'
ROW                   COLUMN+CELL                                               
 1                    column=finfo:dest, timestamp=1715253388203, value=2024    
 1                    column=finfo:source, timestamp=1715253353944, value=alibag
 1                    column=fsch:at, timestamp=1715253412362, value=7:30 AM    
 1                    column=fsch:delay, timestamp=1715253444126, value=30      
 1                    column=fsch:dt, timestamp=1715253430253, value=12:30 PM   
 2                    column=finfo:dest, timestamp=1715253119953, value=alibag  
 2                    column=finfo:source, timestamp=1715253096346, value=nashik
 2                    column=finfo:year, timestamp=1715253146382, value=2025    
 2                    column=fsch:at, timestamp=1715253196355, value=2:00 PM    
 2                    column=fsch:delay, timestamp=1715253296654, value=60      
 2                    column=fsch:dt, timestamp=1715253245533, value=3:00 PM    
 3                    column=finfo:dest, timestamp=1715253637641, value=Nagar   
 3                    column=finfo:source, timestamp=1715253625283, value=Pune  
 3                    column=finfo:year, timestamp=1715253680985, value=2024    
 3                    column=fsch:at, timestamp=1715253742389, value=4:00 PM    
 3                    column=fsch:delay, timestamp=1715253776336, value=10      
 3                    column=fsch:dt, timestamp=1715253763105, value=7:00 PM    
3 row(s) in 0.0570 seconds

hbase(main):027:0> delete 'flight','1','fsch:delay',1715253444126
0 row(s) in 0.0300 seconds

hbase(main):028:0> scan 'flight'
ROW                   COLUMN+CELL                                               
 1                    column=finfo:dest, timestamp=1715253388203, value=2024    
 1                    column=finfo:source, timestamp=1715253353944, value=alibag
 1                    column=fsch:at, timestamp=1715253412362, value=7:30 AM    
 1                    column=fsch:dt, timestamp=1715253430253, value=12:30 PM   
 2                    column=finfo:dest, timestamp=1715253119953, value=alibag  
 2                    column=finfo:source, timestamp=1715253096346, value=nashik
 2                    column=finfo:year, timestamp=1715253146382, value=2025    
 2                    column=fsch:at, timestamp=1715253196355, value=2:00 PM    
 2                    column=fsch:delay, timestamp=1715253296654, value=60      
 2                    column=fsch:dt, timestamp=1715253245533, value=3:00 PM    
 3                    column=finfo:dest, timestamp=1715253637641, value=Nagar   
 3                    column=finfo:source, timestamp=1715253625283, value=Pune  
 3                    column=finfo:year, timestamp=1715253680985, value=2024    
 3                    column=fsch:at, timestamp=1715253742389, value=4:00 PM    
 3                    column=fsch:delay, timestamp=1715253776336, value=10      
 3                    column=fsch:dt, timestamp=1715253763105, value=7:00 PM    
3 row(s) in 0.0440 seconds

hbase(main):029:0> put 'flight','1','fsch:delay',30
0 row(s) in 0.0260 seconds

hbase(main):030:0> scan 'flight'
ROW                   COLUMN+CELL                                               
 1                    column=finfo:dest, timestamp=1715253388203, value=2024    
 1                    column=finfo:source, timestamp=1715253353944, value=alibag
 1                    column=fsch:at, timestamp=1715253412362, value=7:30 AM    
 1                    column=fsch:delay, timestamp=1715254014526, value=30      
 1                    column=fsch:dt, timestamp=1715253430253, value=12:30 PM   
 2                    column=finfo:dest, timestamp=1715253119953, value=alibag  
 2                    column=finfo:source, timestamp=1715253096346, value=nashik
 2                    column=finfo:year, timestamp=1715253146382, value=2025    
 2                    column=fsch:at, timestamp=1715253196355, value=2:00 PM    
 2                    column=fsch:delay, timestamp=1715253296654, value=60      
 2                    column=fsch:dt, timestamp=1715253245533, value=3:00 PM    
 3                    column=finfo:dest, timestamp=1715253637641, value=Nagar   
 3                    column=finfo:source, timestamp=1715253625283, value=Pune  
 3                    column=finfo:year, timestamp=1715253680985, value=2024    
 3                    column=fsch:at, timestamp=1715253742389, value=4:00 PM    
 3                    column=fsch:delay, timestamp=1715253776336, value=10      
 3                    column=fsch:dt, timestamp=1715253763105, value=7:00 PM    
3 row(s) in 0.0770 seconds

hbase(main):031:0> alter 'flight,NAME=>'revenue'
hbase(main):032:0' 
hbase(main):033:0' '
SyntaxError: (hbase):31: syntax error, unexpected tIDENTIFIER

alter 'flight,NAME=>'revenue'
                           ^

hbase(main):034:0> alter 'flight',NAME=>'revenue'
Updating all regions with the new schema...
0/1 regions updated.
1/1 regions updated.
Done.
0 row(s) in 5.7460 seconds

hbase(main):035:0> put 'flight',1,'revenue:in_Rs','45000'
0 row(s) in 0.0720 seconds

hbase(main):036:0> put 'flight',2,'revenue:in_Rs','55000'
0 row(s) in 0.0460 seconds

hbase(main):037:0> put 'flight',3,'revenue:in_Rs','60000'
0 row(s) in 0.0100 seconds

hbase(main):038:0> scan 'flight'
ROW                   COLUMN+CELL                                               
 1                    column=finfo:dest, timestamp=1715253388203, value=2024    
 1                    column=finfo:source, timestamp=1715253353944, value=alibag
 1                    column=fsch:at, timestamp=1715253412362, value=7:30 AM    
 1                    column=fsch:delay, timestamp=1715254014526, value=30      
 1                    column=fsch:dt, timestamp=1715253430253, value=12:30 PM   
 1                    column=revenue:in_Rs, timestamp=1715254138732, value=45000
 2                    column=finfo:dest, timestamp=1715253119953, value=alibag  
 2                    column=finfo:source, timestamp=1715253096346, value=nashik
 2                    column=finfo:year, timestamp=1715253146382, value=2025    
 2                    column=fsch:at, timestamp=1715253196355, value=2:00 PM    
 2                    column=fsch:delay, timestamp=1715253296654, value=60      
 2                    column=fsch:dt, timestamp=1715253245533, value=3:00 PM    
 2                    column=revenue:in_Rs, timestamp=1715254148974, value=55000
 3                    column=finfo:dest, timestamp=1715253637641, value=Nagar   
 3                    column=finfo:source, timestamp=1715253625283, value=Pune  
 3                    column=finfo:year, timestamp=1715253680985, value=2024    
 3                    column=fsch:at, timestamp=1715253742389, value=4:00 PM    
 3                    column=fsch:delay, timestamp=1715253776336, value=10      
 3                    column=fsch:dt, timestamp=1715253763105, value=7:00 PM    
 3                    column=revenue:in_Rs, timestamp=1715254160181, value=60000
3 row(s) in 0.0490 seconds

hbase(main):039:0> 

Now Open new terminal and open hive

[cloudera@quickstart ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.
hive> create external table hnase_flight_new(fno int,fsrc string,fdest string,fsh_at string,fsh_dt string,delay int)
    > stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
    > with serdeproperties("hbase.columns.mapping" = 
    > ":key,finfo:source,finfo:dest,fsch:at,fsch:dt,fsch:delay")
    > TBLPROPERTIES("hbase.table.name"="flight");
OK
Time taken: 40.257 seconds
hive> select *from hbase_flight_new;
FAILED: SemanticException [Error 10001]: Line 1:13 Table not found 'hbase_flight_new'
hive> select *from hnase_flight_new;
OK
1	alibag	2024	7:30 AM	12:30 PM	30
2	nashik	alibag	2:00 PM	3:00 PM	60
3	Pune	Nagar	4:00 PM	7:00 PM	10
Time taken: 2.755 seconds, Fetched: 3 row(s)
hive> select sum(delay) from hnase_flight_new;
Query ID = cloudera_20240509051313_085bd63d-5f73-4c05-8620-aa6d29541d5b
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1715251881039_0001, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1715251881039_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1715251881039_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2024-05-09 05:16:29,779 Stage-1 map = 0%,  reduce = 0%
2024-05-09 05:17:30,041 Stage-1 map = 0%,  reduce = 0%
2024-05-09 05:18:31,150 Stage-1 map = 0%,  reduce = 0%
2024-05-09 05:18:56,529 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 14.29 sec
2024-05-09 05:19:29,112 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 16.12 sec
MapReduce Total cumulative CPU time: 16 seconds 120 msec
Ended Job = job_1715251881039_0001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 16.12 sec   HDFS Read: 8223 HDFS Write: 4 SUCCESS
Total MapReduce CPU Time Spent: 16 seconds 120 msec
OK
100
Time taken: 376.665 seconds, Fetched: 1 row(s)
hive> select avg(delay) from hnase_flight_new;
Query ID = cloudera_20240509052020_e88a41f4-02af-4e7f-8fb1-e368836f4c1b
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1715251881039_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1715251881039_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1715251881039_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2024-05-09 05:21:49,833 Stage-1 map = 0%,  reduce = 0%
2024-05-09 05:23:02,542 Stage-1 map = 0%,  reduce = 0%
2024-05-09 05:23:23,281 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 8.21 sec
2024-05-09 05:23:41,385 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.3 sec
MapReduce Total cumulative CPU time: 10 seconds 300 msec
Ended Job = job_1715251881039_0002
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 10.3 sec   HDFS Read: 8763 HDFS Write: 19 SUCCESS
Total MapReduce CPU Time Spent: 10 seconds 300 msec
OK
33.333333333333336
Time taken: 163.938 seconds, Fetched: 1 row(s)
hive> create index hbase_index
    > on table hnase_flight_new (delay)
    > as 'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'
    > with deferred rebuild;
OK
Time taken: 3.457 seconds
hive> show index on hnase_flight_new
    > ;
OK
hbase_index         	hnase_flight_new    	delay               	default__hnase_flight_new_hbase_index__	compact             	
Time taken: 0.399 seconds, Fetched: 1 row(s)

***********************************Completed*************************************